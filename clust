import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.cluster import KMeans

# Загружаем датасет цветков ириса и сохраняем его в переменную iris_dataset
iris_dataset = load_iris()

# Извлекаем из датасета только два признака - sepal_length и sepal_width и целевую переменную - variety(y)
X = iris_dataset.data[:, :2]
y = iris_dataset.target

# Разделяем данные на тренировочную и тестовую выборки в соотношении 70:30
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Создаем модель LDA и обучаем ее на тренировочных данных
lda = LinearDiscriminantAnalysis()
lda.fit(X_train, y_train)

# Предсказываем значения целевой переменной для тестовых данных
y_pred = lda.predict(X_test)

# Визуализируем предсказанные значения целевой переменной для тестовых данных
plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)
plt.scatter(lda.means_[:, 0], lda.means_[:, 1], s=200, marker='*', c='red')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('LDA Predictions')
plt.show()

# Оставляем только два признака - sepal_length и sepal_width
X = iris_dataset.data[:, :2]

# явно указываем количество кластеров
kmeans = KMeans(n_clusters=3, random_state=42)

# Обучаем модель на данных без целевой переменной
kmeans.fit(X)

# Визуализируем полученную кластеризацию
plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, marker='*', c='red')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.title('KMeans Clustering')
plt.show()
